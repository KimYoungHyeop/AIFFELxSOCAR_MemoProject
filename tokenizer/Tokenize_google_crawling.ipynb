{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenize_google_crawling_2021.12.13",
      "provenance": [],
      "collapsed_sections": [
        "UUZsLXLeX4SK",
        "ffZDrzEmZQqk",
        "9QVd6leBRqLf",
        "N1GegjF3ZZ7u",
        "a9qhru3yw6p8",
        "PFiuem2RKmuB"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a79b5a56b1442f4a5fe897aa5a6e5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c541acf2fde94bfcb0a299a68fe8d23c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c7c623585554730812d0f28e0c94ac6",
              "IPY_MODEL_1033f18c2fbf4631bf2b0a704577670e",
              "IPY_MODEL_f063e17c4ae5417bb04de691de502b7e"
            ]
          }
        },
        "c541acf2fde94bfcb0a299a68fe8d23c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c7c623585554730812d0f28e0c94ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18d26a05c4bc4a53b818dd8f8ff10e10",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_098516d2ef0d4f10a1c5b4c36ac8726b"
          }
        },
        "1033f18c2fbf4631bf2b0a704577670e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7c5bf47d48c48d5823b604a1df4f78d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2645762dc88406eaed2584f13d05514"
          }
        },
        "f063e17c4ae5417bb04de691de502b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54c888fd886241e68789e90661eae42d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 100/100 [12:35&lt;00:00,  1.65s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aba3dccbc77e4edaa6094e1d404958b0"
          }
        },
        "18d26a05c4bc4a53b818dd8f8ff10e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "098516d2ef0d4f10a1c5b4c36ac8726b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7c5bf47d48c48d5823b604a1df4f78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2645762dc88406eaed2584f13d05514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54c888fd886241e68789e90661eae42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aba3dccbc77e4edaa6094e1d404958b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUZsLXLeX4SK"
      },
      "source": [
        "## 크롤링 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DNndTGcXsBp"
      },
      "source": [
        "#!pip install -r /content/drive/MyDrive/requirements.txt\n",
        "# !pip install folium==0.2.1\n",
        "# !pip install urllib3==1.26.6\n",
        "!pip install selenium\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y22nZub3X9HS"
      },
      "source": [
        "from urllib.parse import quote_plus\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from time import sleep\n",
        "import os\n",
        "import re\n",
        "\n",
        "\n",
        "class GoogleSearcher:\n",
        "    def __init__(self, implicitly_wait_time=10):\n",
        "        self.implicitly_wait_time = implicitly_wait_time\n",
        "\n",
        "        self.chrome_options = webdriver.ChromeOptions()\n",
        "        self.chrome_options.add_argument(\"--headless\")\n",
        "        self.chrome_options.add_argument(\"--no-sandbox\")\n",
        "        self.chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    \n",
        "    def __del__(self):\n",
        "        if self.driver:\n",
        "            self.driver.quit()\n",
        "\n",
        "    \n",
        "    def reset_driver(self):\n",
        "        if self.driver:\n",
        "            self.driver.quit() # 드라이버를 재활용 할거면 닫지말아야한다.\n",
        "            \n",
        "        chrome_driver_path = \"chromedriver\"\n",
        "        \n",
        "        self.driver = webdriver.Chrome(chrome_driver_path, options=self.chrome_options)\n",
        "        self.driver.implicitly_wait(self.implicitly_wait_time)\n",
        "\n",
        "\n",
        "    def get_page_soup(self, word):\n",
        "        url = f\"https://www.google.com/search?q={quote_plus(word)}\"\n",
        "\n",
        "        self.driver.get(url)\n",
        "\n",
        "        page_html = self.driver.page_source\n",
        "        page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
        "        return page_soup\n",
        "\n",
        "\n",
        "    def search(self, word, recursion=False):\n",
        "        self.reset_driver()\n",
        "        page_soup = self.get_page_soup(word)\n",
        "\n",
        "        modifier = page_soup.select_one('a.gL9Hy')\n",
        "        if modifier:\n",
        "            word = modifier.text\n",
        "            page_soup = self.get_page_soup(word)\n",
        "\n",
        "        data = page_soup.select(\".g\")\n",
        "        if not data:\n",
        "            if recursion:\n",
        "                print(word)\n",
        "            else:\n",
        "                self.driver.quit()\n",
        "                sleep(3)\n",
        "                return self.search(word, True)\n",
        "\n",
        "        result = []\n",
        "        for g in data:\n",
        "            title = g.select_one(\".LC20lb\")\n",
        "            if title:\n",
        "                result.append(title.text)  # 타이틀\n",
        "            if g.find(\"div\", attrs={\"class\": \"VwiC3b\"}):\n",
        "                result.append(g.select_one(\".VwiC3b\").text)  # 내용\n",
        "\n",
        "        return result, word\n",
        "\n",
        "\n",
        "    def search_highlighted(self, word, recursion=False):\n",
        "        self.reset_driver() # 매번 리셋하지않으면 많은 트래픽으로 봇으로 차단당함\n",
        "        page_soup = self.get_page_soup(word)\n",
        "\n",
        "        modifier = page_soup.select_one('a.gL9Hy')\n",
        "        if modifier:\n",
        "            word = modifier.text\n",
        "            modifier = modifier.text\n",
        "            page_soup = self.get_page_soup(word)\n",
        "\n",
        "        data = page_soup.find_all(\"em\")\n",
        "        if not data:\n",
        "            if recursion:\n",
        "                print(word)\n",
        "            else:\n",
        "                self.driver.quit()\n",
        "                sleep(3)\n",
        "                return self.search_highlighted(word, True)\n",
        "\n",
        "        result = []\n",
        "        for element in data:\n",
        "            result.extend(element.text.split())\n",
        "\n",
        "        return result, modifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7pEZfE_YFtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20f7c06-eee6-4a37-daff-cb8490309f89"
      },
      "source": [
        "google_searcher = GoogleSearcher()\n",
        "google_searcher.search('도어밸트끼임수리')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['안전벨트가 풀리지 않습니다. 어떻게 해야 하나요? DIY 안전 ...',\n",
              "  '11 okt. 2019 — 짧은 Phillips 드라이버를 사용하여 중간 도어 기둥의 바닥판에 있는 나사 4개를 풉니다. 그런 다음 덮개를 살짝 위로 살짝 당겨 제거합니다. 수리의 다음\\xa0...',\n",
              "  '안전벨트가 풀리지 않습니다. 어떻게 해야 하나요? DIY 안전 ...',\n",
              "  '11 okt. 2019 — 짧은 Phillips 드라이버를 사용하여 중간 도어 기둥의 바닥판에 있는 나사 4개를 풉니다. 그런 다음 덮개를 살짝 위로 살짝 당겨 제거합니다. 수리의 다음\\xa0...',\n",
              "  '다양한 수리 솔루션! 관성 벨트 오작동의 주요 원인',\n",
              "  '29 sep. 2019 — 그러나 자가 수리 안전 벨트는 가계 예산에서 상당한 돈을 절약하는 데 도움이 될 것 ... 도어 필러 (중간)의 하단 트림에서 4 개의 볼트가 풀립니다.',\n",
              "  '수리 정비시 끼임 사고를 예방합시다 - THIS4',\n",
              "  '10 mrt. 2021 — ○ 기인물별로는 벨트컨베이어, 천장크레인, 지게차 순으로 사망재해가 많이 발생했으며, 방호설비 설치대상 132건 중 미설치로 인한 사망건수가 115건(\\xa0...',\n",
              "  'K5(DL3) 흡습시 아웃핸들 내부 간극이 좁아져 도어 오픈시 리턴 ...',\n",
              "  '14 okt. 2020 — 자동차 리콜 정보(기아) · K5(DL3) 흡습시 아웃핸들 내부 간극이 좁아져 도어 오픈시 리턴이 안되고 끼임 발생 가능 무상수리 · 댓글 · 자동차 리콜 정보(..',\n",
              "  '카니발 yp 슬라이딩도어 리콜 - 카카오프렌즈 색칠공부',\n",
              "  '24 mei 2018 — ... 제작하여 판매한 카니발(YP) 224,615대는 파워 슬라이딩 도어 내 끼임 ... 서비스센터에서 무상으로 수리(소프트웨어 업데이트)를 받을 수 있다.',\n",
              "  \"경 고 [한국소비자원'비충돌사고(Non-Crash Incident) 저감'경고 ...\",\n",
              "  '28 apr. 2021 — 도어/트렁크/유리창을 열고 닫을 때 신체 일부가 끼이거나 부딪혀 다칠 수 ... 안전벨트는 교통사고 발생 시 차량 탑승자의 생명, 신체를 보호하는\\xa0...',\n",
              "  \"카니발 22.4만대 슬라이딩 도어 리콜…QM6 5만대 '과징금'\",\n",
              "  \"24 mei 2018 — 기아자동차 미니밴 '카니발'이 파워 슬라이딩 도어 제작결함으로 ... 해당 차량은 오는 25일부터 르노삼성차 서비스센터에서 무상 수리받을 수 있다.\",\n",
              "  \"'파워 슬라이딩 도어 결함' 기아 카니발 리콜…QM6·벤츠 등 28만 ...\",\n",
              "  '24 mei 2018 — ... 기아차가 제작·판매한 카니발(YP) 22만4615대는 파워 슬라이딩 도어 내 끼임 ... 서비스센터에서 무상으로 소프트웨어 업데이트 수리를 받을 수 있다.',\n",
              "  \"'도어 결함'기아 카니발 등 30개 차종 29만대 리콜 - 카가이\",\n",
              "  '24 mei 2018 — ... 가 제작·판매한 카니발(YP) 22만4615대는 파워 슬라이딩 도어 내 끼임 방지 ... 해당차량은 24일부터 기아차 서비스센터에서 무상 수리를 받을 수\\xa0...'],\n",
              " '도어 벨트 끼임 수리')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "854LbKvgYbpZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7090a4e6-1c1e-4684-d6b2-d837840bcc9f"
      },
      "source": [
        "google_searcher.search_highlighted('전파넬보수')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['전판넬보수',\n",
              "  '전판넬',\n",
              "  '판넬보수',\n",
              "  '보수',\n",
              "  '보수',\n",
              "  '전',\n",
              "  '판넬',\n",
              "  '보수',\n",
              "  '판넬',\n",
              "  '전',\n",
              "  '판넬',\n",
              "  '보수',\n",
              "  '전',\n",
              "  '판넬',\n",
              "  '판넬',\n",
              "  '보수',\n",
              "  '보수',\n",
              "  '전',\n",
              "  '판넬',\n",
              "  '판넬',\n",
              "  '보수',\n",
              "  '판넬',\n",
              "  '전',\n",
              "  '전',\n",
              "  '판넬보수',\n",
              "  '판넬보수',\n",
              "  '판넬보수',\n",
              "  '판넬',\n",
              "  '전',\n",
              "  '보수'],\n",
              " None)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifCIMdEvYxbS"
      },
      "source": [
        "## 기능 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffZDrzEmZQqk"
      },
      "source": [
        "### 제목과 문장 텍스트를 보는 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmdXC1SXYiwA"
      },
      "source": [
        "def create_ngram_dict(word):\n",
        "    result = dict()\n",
        "\n",
        "    words = word.split()\n",
        "    combo = ''.join(words)\n",
        "    \n",
        "    start = 0\n",
        "    for word in words:\n",
        "        for i in range(len(word)):\n",
        "            result[start+i] = [word[i:i+n] for n in range(1, len(word)+1-i)]\n",
        "        start += len(word)\n",
        "\n",
        "    return result, combo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn16kqvKZD2R"
      },
      "source": [
        "def create_max_combos(combo, ngram_dict, score_multipe=2):\n",
        "    len_combo = len(combo)\n",
        "    max_combos_list = [(-1, None)] * len_combo  # (최대점수, 그 경우 가능한 토큰조합들)\n",
        "\n",
        "    def find_max_combos(idx=0):\n",
        "        if max_combos_list[idx][0] == -1:\n",
        "            max_score = score_multipe\n",
        "            tokens = []\n",
        "            for token, score in ngram_dict[idx]:\n",
        "                assert(idx + len(token) <= len_combo)\n",
        "\n",
        "                if idx + len(token) < len_combo:\n",
        "                    score +=find_max_combos(idx + len(token))\n",
        "                if max_score == score:\n",
        "                    tokens.append(token)\n",
        "                elif max_score < score:\n",
        "                    tokens = [token]\n",
        "                    max_score = score\n",
        "\n",
        "            max_combos = []\n",
        "            if len(tokens) == 0:\n",
        "                max_score = 0\n",
        "                max_combos.append([combo[idx:]])\n",
        "            else:\n",
        "                for token in tokens:\n",
        "                    if idx+len(token) >= len_combo:\n",
        "                        max_combos.append([token])\n",
        "                    else:\n",
        "                        for max_combo in max_combos_list[idx + len(token)][1]:\n",
        "                            max_combos.append([token] + max_combo)\n",
        "                \n",
        "            max_combos_list[idx] = (max_score, max_combos)\n",
        "        \n",
        "        return max_combos_list[idx][0]\n",
        "\n",
        "    max_score = find_max_combos()\n",
        "    return max_score, max_combos_list[0][1], max_combos_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0lLw9F_ZGOA"
      },
      "source": [
        "import re\n",
        "\n",
        "def tokenize_combo(searcher, combo, multiple=5, m_penalty=1, threshold=None):\n",
        "    '''\n",
        "    m_penalty : 검색에서 등장하지 않는 토큰에 대해 주는 패널티\n",
        "    threshold : 최고 점수가 아니더라도 이 최소 등장 빈도를 넘길 경우,\n",
        "                잘라서 토큰화시킨다.\n",
        "    '''\n",
        "    words, combo = searcher.search(combo)\n",
        "    words = re.sub(r'[^가-힣]', ' ', ' '.join(words)).split()\n",
        "\n",
        "    ngram_dict, combo = create_ngram_dict(combo)\n",
        "    for i, tokens in ngram_dict.items():\n",
        "        ngram_dict[i] = sorted([(t, words.count(t)*multiple) for t in tokens], key=lambda x: x[1], reverse=True)\n",
        "        ngram_dict[i] = [(t, c) if c > 0 else (t, c-m_penalty)  for t, c in ngram_dict[i]]\n",
        "\n",
        "    score, max_combo, combos_info = create_max_combos(combo, ngram_dict, multiple)\n",
        "    return max(max_combo, key=lambda x: -len(x)), score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtvJnPPjZI1J",
        "outputId": "68d34868-1804-4ac8-f0f0-8bd23f0ce9da"
      },
      "source": [
        "tokenize_combo(google_searcher, '전파넬보수')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['전', '파넬', '보수'], 70)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QVd6leBRqLf"
      },
      "source": [
        "### 유틸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vZoeLPqkJn0",
        "outputId": "2387ad1f-c9cc-4e36-bf0b-8097878e63a7"
      },
      "source": [
        "!pip install jamo\n",
        "from jamo import h2j, j2hcj\n",
        "\n",
        "\n",
        "def calc_distance(a, b):\n",
        "    ''' 레벤슈타인 거리 계산하기 '''\n",
        "    if a == b:\n",
        "        return 0  # 같으면 0을 반환\n",
        "\n",
        "    a, b = j2hcj(h2j(a)), j2hcj(h2j(b))  # 자모 단위로 나누기\n",
        "    a_len = len(a)  # a 길이\n",
        "    b_len = len(b)  # b 길이\n",
        "    if a == \"\":\n",
        "        return b_len\n",
        "    if b == \"\":\n",
        "        return a_len\n",
        "    # 2차원 표 (a_len+1, b_len+1) 준비하기\n",
        "    matrix = [[] for i in range(a_len+1)]\n",
        "    for i in range(a_len+1):  # 0으로 초기화\n",
        "        matrix[i] = [0 for j in range(b_len+1)]\n",
        "    # 0일 때 초깃값을 설정\n",
        "    for i in range(a_len+1):\n",
        "        matrix[i][0] = i\n",
        "    for j in range(b_len+1):\n",
        "        matrix[0][j] = j\n",
        "\n",
        "    for i in range(1, a_len+1):\n",
        "        ac = a[i-1]\n",
        "        for j in range(1, b_len+1):\n",
        "            bc = b[j-1]\n",
        "            cost = 0 if (ac == bc) else 1\n",
        "            matrix[i][j] = min([\n",
        "                matrix[i-1][j] + 1,     # 문자 삽입\n",
        "                matrix[i][j-1] + 1,     # 문자 제거\n",
        "                matrix[i-1][j-1] + cost  # 문자 변경\n",
        "            ])\n",
        "\n",
        "    return matrix[a_len][b_len]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: jamo\n",
            "Successfully installed jamo-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJFsLW_9ZPaC"
      },
      "source": [
        "def is_left_more_similar(trg, left, right):\n",
        "    return calc_distance(trg, left) < calc_distance(trg, right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1GegjF3ZZ7u"
      },
      "source": [
        "### 구글 자체 강조 단어만을 보는 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWWH6mizZ5S5"
      },
      "source": [
        "def combine_max_combo(combo, likely_dict):\n",
        "    len_combo = len(combo)\n",
        "    max_combos_list = [(-1, None)] * len_combo  # (최대점수, 그 경우 가능한 토큰조합들)\n",
        "\n",
        "    def find_max_combos(idx=0):\n",
        "        if max_combos_list[idx][0] == -1:\n",
        "            tokens = []\n",
        "            max_score = 0\n",
        "            single_score, single_token = 0, None\n",
        "            for token, score in likely_dict[idx]:\n",
        "                if idx + len(token) > len_combo:\n",
        "                    continue\n",
        "                elif idx + len(token) < len_combo:\n",
        "                    score += find_max_combos(idx + len(token))\n",
        "                    if score <= 0:\n",
        "                        continue\n",
        "                else:\n",
        "                    if score == single_score:\n",
        "                        if is_left_more_similar(combo[idx:], token, single_token):\n",
        "                            single_score, single_token = score, token\n",
        "                    elif score > single_score:\n",
        "                        single_score, single_token = score, token\n",
        "\n",
        "                if max_score == score:\n",
        "                    tokens.append(token)\n",
        "                elif max_score < score:\n",
        "                    tokens = [token]\n",
        "                    max_score = score\n",
        "\n",
        "            max_combos = []\n",
        "            for token in tokens:\n",
        "                if idx + len(token) == len_combo:\n",
        "                    max_combos.append([token])\n",
        "                else:\n",
        "                    for max_combo in max_combos_list[idx + len(token)][1]:\n",
        "                        max_combos.append([token] + max_combo)\n",
        "\n",
        "            if single_token and single_score < max_score:\n",
        "                max_combos.append([single_token])\n",
        "            max_combos_list[idx] = (max_score, max_combos)\n",
        "        \n",
        "        return max_combos_list[idx][0]\n",
        "\n",
        "    if find_max_combos() != 0:\n",
        "        return sorted(max_combos_list[0][1], key=lambda x: len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkbRVWOyaCQh"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def create_likely_dict(combo, words):\n",
        "    result = defaultdict(list)\n",
        "\n",
        "    for token in set(words):\n",
        "        starts = []\n",
        "        min_score = 99\n",
        "        for i in range(len(combo)):\n",
        "            score = calc_distance(token, combo[i:i+len(token)]) # todo: 끝에는 잘라서 비교해보기\n",
        "            if score == min_score:\n",
        "                starts.append(i)\n",
        "            elif score < min_score:\n",
        "                starts = [i]\n",
        "                min_score = score\n",
        "        \n",
        "        for i in starts:\n",
        "            result[i].append((token, words.count(token)))\n",
        "    \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zesuM9t0amrJ"
      },
      "source": [
        "def tokenize_multiple_combo(searcher, combo):\n",
        "    words, _ = searcher.search_highlighted(combo)\n",
        "    likely_dict = create_likely_dict(combo, words)\n",
        "\n",
        "    return combine_max_combo(combo, likely_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE-g-SUEanwI",
        "outputId": "ae85b0c5-1170-423b-f8b7-238657510bd7"
      },
      "source": [
        "tokenize_multiple_combo(google_searcher, '공기압보충후')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['공기압', '보충후'], ['공기압', '보충', '후']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9qhru3yw6p8"
      },
      "source": [
        "### 동사등이 섞인 문장에서 추출하는 경우"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swbRCWOEyUda"
      },
      "source": [
        "!pip install sentencepiece\n",
        "!pip install konlpy\n",
        "!pip install customized_konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7eFFP6yk3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57a2d33-5f21-4c8b-9336-70a998fa05f3"
      },
      "source": [
        "import sentencepiece as spm\n",
        "from konlpy.tag import Kkma, Komoran\n",
        "from ckonlpy.tag import Twitter\n",
        "\n",
        "kkma = Kkma()\n",
        "\n",
        "okt = Twitter()\n",
        "okt.dictionary._pos2words = {}\n",
        "\n",
        "\n",
        "def add_except_konlpy(okt):\n",
        "    okt.dictionary._pos2words = {}\n",
        "    with open('/content/drive/MyDrive/customized_konlpy/okt_nouns.txt', 'r') as f:\n",
        "        nouns_okt = f.read().split()\n",
        "\n",
        "    with open('/content/drive/MyDrive/customized_konlpy/kkma_nouns.txt', 'r') as f:\n",
        "        nouns_kkma = f.read().split()\n",
        "\n",
        "    okt.add_dictionary(nouns_okt, 'Noun')\n",
        "    okt.add_dictionary(['하니'], 'Verb')\n",
        "    okt.add_dictionary(['너무', '아예'], 'Adverb')\n",
        "\n",
        "    return nouns_kkma\n",
        "\n",
        "\n",
        "kkma_filter = add_except_konlpy(okt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I710rY160vk5",
        "outputId": "d75481b9-0826-419e-a053-448b5e47b1e3"
      },
      "source": [
        "s = '전파넬교환'\n",
        "print(kkma.pos(s))\n",
        "print(okt.pos(s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('전', 'NNG'), ('파넬', 'NNG'), ('교환', 'NNG')]\n",
            "[('전파', 'Noun'), ('넬', 'Noun'), ('교환', 'Noun')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoNvj1VFzZDB",
        "outputId": "c1be7c7e-07b7-4396-b3e6-fa1f4e1dd930"
      },
      "source": [
        "s = '정지에서출발할때떨림발생건'\n",
        "a, m = google_searcher.search_highlighted(s)\n",
        "print(s)\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정지에서출발할때떨림발생건\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['떨림',\n",
              " '에서',\n",
              " '떨림',\n",
              " '출발',\n",
              " '할',\n",
              " '때',\n",
              " '떨림',\n",
              " '에',\n",
              " '에서',\n",
              " '정지',\n",
              " '에',\n",
              " '에서',\n",
              " '할',\n",
              " '출발',\n",
              " '할때',\n",
              " '정지',\n",
              " '에서',\n",
              " '떨림',\n",
              " '정지',\n",
              " '출발',\n",
              " '정지할때',\n",
              " '할때',\n",
              " '할때',\n",
              " '떨리는',\n",
              " '출발',\n",
              " '에서',\n",
              " '에',\n",
              " '떨림',\n",
              " '출발',\n",
              " '때',\n",
              " '에',\n",
              " '할',\n",
              " '때는',\n",
              " '출발',\n",
              " '정지',\n",
              " '정지',\n",
              " '출발',\n",
              " '에',\n",
              " '할',\n",
              " '때']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZgdxlZ8folF"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def create_continuous_likely_dict(combo, words):\n",
        "    tokens_list = defaultdict(list)\n",
        "    len_combo = len(combo)\n",
        "\n",
        "    # 각 키워드의 위치찾기\n",
        "    for token in sorted(list(set(words)), key=lambda x: len(x)):\n",
        "        len_token = len(token)\n",
        "        min_score = 99\n",
        "        starts = []\n",
        "        for i in range(len_combo):\n",
        "            score = calc_distance(token, combo[i:i+len_token])\n",
        "            if score == min_score:\n",
        "                starts.append(i)\n",
        "            elif score < min_score:\n",
        "                starts = [i]\n",
        "                min_score = score\n",
        "        \n",
        "        for i in starts:\n",
        "            tokens_list[i].append((token, len_token, words.count(token), min_score))\n",
        "\n",
        "    # 자모 편집거리가 최소가 되는 키워드 조합구성\n",
        "    new_combo = [' '] * len_combo\n",
        "\n",
        "    for s in sorted(tokens_list.keys()):\n",
        "        mt, ml, mc, ms = ' ', 1, 'except_13', 99\n",
        "\n",
        "        tokens_list[s].sort(key=lambda x: x[1])\n",
        "        for token, len_token, count, score in tokens_list[s]:\n",
        "            if ml == len_token:\n",
        "                if score < ms:\n",
        "                    mt, ml, mc, ms = token, len_token, count, score\n",
        "                # elif score == ms:\n",
        "                #     print(f'except 같은 범위에 다른 글자인데, 편집거리가 같음 : {combo}, {i}:{token},{mt}')\n",
        "            else: # ml < len_token\n",
        "                if token[:ml] != mt:\n",
        "                    local_score = calc_distance(token[:ml], combo[s:s+ml])\n",
        "                    if local_score < ms:\n",
        "                        mt, ml, mc, ms = token, len_token, count, score\n",
        "                    # elif local_score == ms:\n",
        "                    #     print(f'except 같은 범위에 다른 글자인데, 편집거리가 같음 : {combo}, {i}:{token},{mt}')\n",
        "                else:\n",
        "                    mt, ml, mc, ms = token, len_token, count, score\n",
        "\n",
        "        for i, char in enumerate(mt[:len_combo-s], start=s):\n",
        "            if new_combo[i] != ' ' and char != new_combo[i]:\n",
        "                if calc_distance(new_combo[i], combo[i]) < calc_distance(char, combo[i]):\n",
        "                    break\n",
        "            new_combo[i] = char\n",
        "\n",
        "    new_combo = ''.join(new_combo)\n",
        "\n",
        "    # 키워드를 채우고 빈 공간 채우기(점수는 None)\n",
        "    check_list = [False] * len_combo\n",
        "    result = dict()#defaultdict(list)\n",
        "\n",
        "    for i, tokens in tokens_list.items():\n",
        "        temp = []\n",
        "        max_len = 0\n",
        "        for token, len_token, count, _ in tokens:\n",
        "            if token in new_combo:\n",
        "                temp.append((token, count))\n",
        "                max_len = max(max_len, len_token)\n",
        "\n",
        "        if len(temp) > 0:\n",
        "            result[i] = temp\n",
        "            for j in range(i, min(i+max_len, len_combo)):\n",
        "                check_list[j] = True\n",
        "\n",
        "    for i, b in enumerate(check_list):\n",
        "        if b == False:\n",
        "            e = i + 1\n",
        "            for j in range(e, len_combo):\n",
        "                if check_list[j]:\n",
        "                    break\n",
        "                e += 1\n",
        "                check_list[j] = True\n",
        "            new_combo = new_combo[:i] + combo[i:e] + new_combo[e:]\n",
        "            assert(i not in result.keys())\n",
        "            result[i] = [(combo[i:e], 0)]\n",
        "\n",
        "    return result, new_combo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFl2pRmUckm2",
        "outputId": "8a0d9b43-026e-47ec-c052-d3838b2e71ca"
      },
      "source": [
        "b, s = create_continuous_likely_dict(s, a)\n",
        "print(s)\n",
        "b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정지에서출발할때떨림발생건\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [('정지', 5)],\n",
              " 2: [('에', 5), ('에서', 5)],\n",
              " 4: [('출발', 7)],\n",
              " 6: [('할', 4), ('할때', 3)],\n",
              " 7: [('때', 3)],\n",
              " 8: [('떨림', 5)],\n",
              " 10: [('발생건', 0)]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT7W5j0yGGay"
      },
      "source": [
        "delete_tags = ['Adjective', 'Adverb', 'Conjunction', 'Eomi', 'Josa', 'Verb', 'VerbPrefix']\n",
        "\n",
        "def fill_tokens(combo, likely_dict, pos_tags):\n",
        "    for _ in range(10): # while -> 예외 시 무한 루프 방지\n",
        "        add_list = []\n",
        "        remove_list = []\n",
        "\n",
        "        starts = set(likely_dict.keys())\n",
        "        starts.add(len(combo))\n",
        "        ends = {0,}\n",
        "\n",
        "        for s in sorted(likely_dict.keys()):\n",
        "            if s not in ends:   # 완료입니다 -> (완료x)입니다\n",
        "                before = None\n",
        "                is_before_noun = False\n",
        "                is_after_noun = False\n",
        "                ts, te, tl = 0, 0, 0\n",
        "                for i, (t, p) in enumerate(pos_tags):\n",
        "                    te = ts + len(t)\n",
        "                    if te == s: # 앞 토큰(인덱스로 끝나는 토큰)\n",
        "                        ls = te\n",
        "                        for t, p in pos_tags[:i+1][::-1]:\n",
        "                            if not p in delete_tags:\n",
        "                                is_before_noun = True\n",
        "                            ls -= len(t)\n",
        "                            if ls in starts:\n",
        "                                before = (ls, combo[ls:te])\n",
        "                                break\n",
        "                    elif ts == s: # 뒷 토큰(인덱스로 시작하는 토큰)\n",
        "                        le = ts\n",
        "                        for t, p in pos_tags[i:]:\n",
        "                            if not p in delete_tags:\n",
        "                                is_after_noun = True\n",
        "                                break\n",
        "                            le += len(t)\n",
        "                            if le in starts:\n",
        "                                break\n",
        "                        break\n",
        "                    ts = te\n",
        "\n",
        "                if before and (is_before_noun == False or is_after_noun == False):\n",
        "                    add_list.append(before) # (시작키값, 토큰)\n",
        "                else:\n",
        "                    remove_list.append((s, None)) # (시작키값, 모두 지우기 기호)\n",
        "                    starts.remove(s)\n",
        "                        \n",
        "            for j, (token, _) in enumerate(likely_dict[s]):\n",
        "                e = len(token) + s\n",
        "                \n",
        "                if e not in starts: # 수동모드에서는 -> 수동/모드에서는(에서는x)\n",
        "                    after = None\n",
        "                    is_after_noun = False\n",
        "                    ts, te, tl = 0, 0, 0\n",
        "                    for i, (t, p) in enumerate(pos_tags):\n",
        "                        if ts == e: # 뒷 토큰(인덱스로 시작하는 토큰)\n",
        "                            le = ts\n",
        "                            for t, p in pos_tags[i:]:\n",
        "                                if not p in delete_tags:\n",
        "                                    is_after_noun = True\n",
        "                                    break\n",
        "                                le += len(t)\n",
        "                                if le in starts:\n",
        "                                    break\n",
        "                            if is_after_noun == False:\n",
        "                                after = (e, combo[e:le])\n",
        "                            break\n",
        "                        ts += len(t)\n",
        "\n",
        "                    if after:\n",
        "                        add_list.append(after) # (시작키값, 토큰)\n",
        "                        ends.add(e)\n",
        "                    else:\n",
        "                        remove_list.append((s, j)) # (시작키값, 리스트인덱스)\n",
        "                else:\n",
        "                    ends.add(e)\n",
        "\n",
        "        for s, idx in remove_list:\n",
        "            if idx == None:\n",
        "                del(likely_dict[s])\n",
        "            else:\n",
        "                likely_dict[s].pop(idx)\n",
        "                if len(likely_dict[s]) == 0:\n",
        "                    del(likely_dict[s])\n",
        "\n",
        "        for s, token in add_list:\n",
        "            if s in likely_dict.keys():\n",
        "                likely_dict[s].append((token, 0))\n",
        "            else:\n",
        "                likely_dict[s] = [(token, 0)]\n",
        "\n",
        "        if len(remove_list) == 0 and len(add_list) == 0:\n",
        "            break\n",
        "    else:\n",
        "        raise Exception()\n",
        "\n",
        "    return likely_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYuAtbn8awJZ",
        "outputId": "281e0c49-55ed-415e-8646-292171debfd4"
      },
      "source": [
        "b, s = create_continuous_likely_dict(s, a)\n",
        "p = okt.pos(s)\n",
        "print(b)\n",
        "fill_tokens(s, b, p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{6: [('할', 4), ('할때', 3)], 2: [('에', 5), ('에서', 5)], 7: [('때', 3)], 4: [('출발', 7)], 8: [('떨림', 5)], 0: [('정지', 5)], 10: [('발생건', 0)]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: [('정지', 5)],\n",
              " 2: [('에서', 5)],\n",
              " 4: [('출발', 7)],\n",
              " 6: [('할', 4), ('할때', 3)],\n",
              " 7: [('때', 3)],\n",
              " 8: [('떨림', 5)],\n",
              " 10: [('발생건', 0)]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6bLiLIAM1eS"
      },
      "source": [
        "def create_combo_list(combo, likely_dict):\n",
        "    len_combo = len(combo)\n",
        "    max_combos_list = [(None, None)] * len_combo  # (최대점수, 그 경우 가능한 토큰조합들)\n",
        "\n",
        "    def find_max_combos(idx=0):\n",
        "        if max_combos_list[idx][0] == None:\n",
        "            tokens = []\n",
        "            max_score = -1\n",
        "            for token, score in likely_dict[idx]:\n",
        "                if idx + len(token) > len_combo: # 끝을 넘은 경우\n",
        "                    print(f'except 16 : {combo}') # 앞의 likely_dict를 생성하면서 모두제거 되었다고 가정\n",
        "\n",
        "                elif idx + len(token) < len_combo:\n",
        "                    next_score = find_max_combos(idx + len(token))\n",
        "                    if next_score < 0:\n",
        "                        continue\n",
        "                    score += next_score\n",
        "\n",
        "                tokens.append((token, score))\n",
        "                max_score = max(max_score, score)\n",
        "\n",
        "            max_combos = []\n",
        "            for token, score in tokens:\n",
        "                if idx + len(token) == len_combo or len(max_combos_list[idx + len(token)][1]) == 0:\n",
        "                    max_combos.append([(idx, token, score)])\n",
        "                else:\n",
        "                    for max_combo in max_combos_list[idx + len(token)][1]:\n",
        "                        max_combos.append([(idx, token, score)] + max_combo)\n",
        "\n",
        "            max_combos_list[idx] = (max_score, max_combos)\n",
        "        \n",
        "        return max_combos_list[idx][0]\n",
        "\n",
        "    find_max_combos()\n",
        "    return sorted(max_combos_list[0][1], key=lambda x: -len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDQRxJ1BW66k",
        "outputId": "bd00692d-913b-426b-ee38-57f1e55e1d3f"
      },
      "source": [
        "b, s = create_continuous_likely_dict(s, a)\n",
        "c = fill_tokens(s, b, p)\n",
        "create_combo_list(s, c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, '정지', 29),\n",
              "  (2, '에서', 24),\n",
              "  (4, '출발', 19),\n",
              "  (6, '할', 12),\n",
              "  (7, '때', 8),\n",
              "  (8, '떨림', 5),\n",
              "  (10, '발생건', 0)],\n",
              " [(0, '정지', 29),\n",
              "  (2, '에서', 24),\n",
              "  (4, '출발', 19),\n",
              "  (6, '할때', 8),\n",
              "  (8, '떨림', 5),\n",
              "  (10, '발생건', 0)]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHn1zpAXM6Eg"
      },
      "source": [
        "def tokenize_all_case(searcher, combo):\n",
        "    '''\n",
        "    TODO : 구글 서치를 바꿔야한다. (시동불가상태 -> 이동불가상태) 잘못된검색으로 변한다.\n",
        "    즉, 일단 기존 검색으로 찾아보고 빈칸이 생기거나하면 추천검색으로 넘어가는식으로 바꿔야한다.\n",
        "    '''\n",
        "    if len(combo) == 1:\n",
        "        return combo, [[(0, combo, -1)]], None, 'one_char'\n",
        "\n",
        "    try:\n",
        "        words, modifier = searcher.search_highlighted(combo)\n",
        "    except:\n",
        "        return None, 'search_failed', None, None\n",
        "    if not words:   # 예외2 : 검색이 안됨\n",
        "        return None, 'search_failed', None, None\n",
        "\n",
        "    combo_search = re.sub('\\s+', '', modifier) if modifier else combo\n",
        "\n",
        "    words = [w for w in words if not bool(re.search('[a-zA-Z]', w))]\n",
        "    likely_dict, new_combo = create_continuous_likely_dict(combo_search, words)\n",
        "\n",
        "    if modifier:\n",
        "        if combo_search != new_combo:\n",
        "            print(f'mod_except : {combo} -> {new_combo} != {modifier}')\n",
        "            return new_combo, 'mod_except', None, None\n",
        "        pos_tags = okt.pos(modifier)\n",
        "    else:\n",
        "        pos_tags = okt.pos(new_combo)\n",
        "\n",
        "    # TODO : 길이 7,8이상인면서 konlpy로 비명사로 중간에 잘리고, 검색으로도 잘렸을 경우 문장 분리해보기\n",
        "    # ex) 차량지상으로견인조치 -> 차량지상으로 / 견인조치 -> 나눠서 다시 토큰나이즈 실행\n",
        "\n",
        "    try:\n",
        "        likely_dict = fill_tokens(new_combo, likely_dict, pos_tags)\n",
        "        result = create_combo_list(new_combo, likely_dict)\n",
        "        starts = sorted(likely_dict.keys())\n",
        "    except:\n",
        "        return new_combo, 'try_except', None, None\n",
        "\n",
        "    return new_combo, result, pos_tags, starts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6McVRetH3BE1",
        "outputId": "a8e4b499-6245-404a-a648-eec904688fac"
      },
      "source": [
        "tokenize_all_case(google_searcher, '정지에서출발할때떨림발생건')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('정지에서출발할때떨림발생건',\n",
              " [[(0, '정지', 29),\n",
              "   (2, '에서', 24),\n",
              "   (4, '출발', 19),\n",
              "   (6, '할', 12),\n",
              "   (7, '때', 8),\n",
              "   (8, '떨림', 5),\n",
              "   (10, '발생건', 0)],\n",
              "  [(0, '정지', 29),\n",
              "   (2, '에서', 24),\n",
              "   (4, '출발', 19),\n",
              "   (6, '할때', 8),\n",
              "   (8, '떨림', 5),\n",
              "   (10, '발생건', 0)]],\n",
              " [('정지', 'Noun'),\n",
              "  ('에서', 'Josa'),\n",
              "  ('출발', 'Noun'),\n",
              "  ('할', 'Verb'),\n",
              "  ('때', 'Noun'),\n",
              "  ('떨림', 'Verb'),\n",
              "  ('발생', 'Noun'),\n",
              "  ('건', 'Noun')],\n",
              " [0, 2, 4, 6, 7, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKPL7kxO6cOH"
      },
      "source": [
        "def extract_nouns(searcher, combo):\n",
        "    new_combo, tokens_list, pos_tags, starts = tokenize_all_case(searcher, combo)\n",
        "\n",
        "    if isinstance(tokens_list, str):\n",
        "        return None, tokens_list\n",
        "    elif starts == 'one_char':\n",
        "        return new_combo, tokens_list\n",
        "\n",
        "    probable_info = []\n",
        "\n",
        "    pi, ps = 0, 0\n",
        "    for s in starts:\n",
        "        find_start = True\n",
        "        for t, p in pos_tags[pi:]:\n",
        "            pe = ps + len(t)\n",
        "            if find_start:\n",
        "                if s == ps:\n",
        "                    find_start = False\n",
        "                elif s < ps:\n",
        "                    break\n",
        "                pi += 1\n",
        "            else:\n",
        "                if p not in delete_tags:\n",
        "                    break\n",
        "                if ps in starts:\n",
        "                    probable_info.append((ps, pe, t))\n",
        "                    break\n",
        "            ps = pe\n",
        "\n",
        "    for tokens in tokens_list:\n",
        "        pi = 0\n",
        "        for i, (s, token, _) in enumerate(tokens):\n",
        "            is_delete = False\n",
        "            for ps, pe, pt in probable_info[pi:]:\n",
        "                if s == ps:\n",
        "                    is_delete = True\n",
        "                    break\n",
        "                elif s < ps:\n",
        "                    if s + len(token) > ps:\n",
        "                        is_delete = True\n",
        "                    break\n",
        "                elif s > ps:\n",
        "                    if s < pe:\n",
        "                        is_delete = True\n",
        "                        break\n",
        "                pi += 1\n",
        "            if is_delete:\n",
        "                tokens[i] = (s, None, None)\n",
        "\n",
        "    return new_combo, tokens_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVzK9sIb2lko",
        "outputId": "a2b44b80-aa47-4d1f-d34c-791a1a77147e"
      },
      "source": [
        "extract_nouns(google_searcher, '거제시외버스터미널')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('거제시외버스터미널',\n",
              " [[(0, '거제', 20), (2, '시외', 15), (4, '버스', 10), (6, '터미널', 6)],\n",
              "  [(0, '거제', 20), (2, '시외', 15), (4, '버스터미널', 4)],\n",
              "  [(0, '거제', 20), (2, '시외버스', 7), (6, '터미널', 6)],\n",
              "  [(0, '거제', 20), (2, '시외버스터미널', 2)],\n",
              "  [(0, '거제시외버스터미널', 2)]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG9oIKy79Dzo"
      },
      "source": [
        "## 토큰화 및 명사추출"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFiuem2RKmuB"
      },
      "source": [
        "### 파일열기 및 유틸 기능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNKkWDZ09C_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cac5f9-47fb-421f-ce72-2873184360ef"
      },
      "source": [
        "with open('/content/drive/MyDrive/split_list.txt', 'r') as f:\n",
        "    split_list = f.read().split()\n",
        "\n",
        "print(len(split_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azX61lpDc4WP"
      },
      "source": [
        "delete_tags_kkma = ['V', 'J', 'M', 'E']\n",
        "\n",
        "def split_only_noun_combo(data):\n",
        "    combo_list = []\n",
        "    only_non_noun_combo_list = []\n",
        "\n",
        "    for combo in data:\n",
        "        has_nouns_okt = False\n",
        "        has_nouns_kkma = False\n",
        "\n",
        "        tokens_okt = okt.pos(combo, norm=True)\n",
        "        for token, p in tokens_okt:\n",
        "            if p not in delete_tags:\n",
        "                has_nouns_okt = True\n",
        "                break\n",
        "\n",
        "        tokens_kkma = kkma.pos(combo)\n",
        "        for token, p in tokens_kkma:\n",
        "            if p[0] not in delete_tags_kkma:\n",
        "                has_nouns_kkma = True\n",
        "                break\n",
        "\n",
        "        if has_nouns_kkma == False or has_nouns_okt == False:\n",
        "            for t in kkma_filter:\n",
        "                if t in combo:\n",
        "                    combo_list.append(combo)\n",
        "                    break\n",
        "            else:\n",
        "                only_non_noun_combo_list.append((combo, tokens_kkma))\n",
        "        else:\n",
        "            combo_list.append(combo)\n",
        "\n",
        "\n",
        "    return combo_list, only_non_noun_combo_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMPTLNccekpW",
        "outputId": "0d55d3e1-99f6-4c8f-9682-7fc080f6b3a5"
      },
      "source": [
        "combo_list, only_non_noun_combo_list = split_only_noun_combo(split_list)\n",
        "print(len(combo_list))\n",
        "print(len(only_non_noun_combo_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7101\n",
            "854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZND03vF8LvZ4"
      },
      "source": [
        "def clean_nouns_list(nouns_list):\n",
        "    result = []\n",
        "\n",
        "    for src, trg, tokens_list in nouns_list:\n",
        "        local_group = []\n",
        "        si = 0\n",
        "        reset = True\n",
        "        group = []\n",
        "        for ei, (e, token, _) in enumerate(tokens_list[0]):\n",
        "            if reset:\n",
        "                s = e\n",
        "                si = ei\n",
        "                reset = False\n",
        "            if token != None:\n",
        "                if ei == len(tokens_list[0]) - 1:\n",
        "                    ei += 1\n",
        "                    e = len(trg)\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            reset = True        \n",
        "            local_group = [tokens_list[0][si:ei]]\n",
        "\n",
        "            for tokens in tokens_list[1:]:\n",
        "                lsi = None\n",
        "                for lei, (ls, t, _) in enumerate(tokens):\n",
        "                    if ls == s:\n",
        "                        if t == None:\n",
        "                            break\n",
        "                        lsi = lei\n",
        "                    if ls > e:\n",
        "                        break\n",
        "                    elif ls < e:\n",
        "                        if lei == len(tokens) - 1:\n",
        "                            lei += 1\n",
        "                        else:\n",
        "                            continue\n",
        "\n",
        "                    if lsi == None:\n",
        "                        break\n",
        "\n",
        "                    local_tokens = tokens[lsi:lei]\n",
        "                    \n",
        "                    is_unique = True\n",
        "                    for lt in local_group:\n",
        "                        if lt == None:\n",
        "                            is_unique =False\n",
        "                            break\n",
        "                        if len(lt) != len(local_tokens):\n",
        "                            continue\n",
        "                        for a, b in zip(lt, local_tokens):\n",
        "                            if a[0] != b[0]:\n",
        "                                break\n",
        "                        else:   # for문을 모두 만족, 완벽히 일치하는게 이미 존재하는 경우\n",
        "                            is_unique = False\n",
        "                            break\n",
        "                    \n",
        "                    if is_unique and len(local_tokens) > 0:\n",
        "                        local_group.append(local_tokens)\n",
        "\n",
        "            if len(local_group[0]) > 0:\n",
        "                group.append((src[s:e], trg[s:e], local_group))\n",
        "        result.append((src, group))\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3e3C8uh_9WI"
      },
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def tokenize(combo_list, s, e):\n",
        "    nouns_list = []\n",
        "    zero_noun_list = []\n",
        "    except_combo_list = []\n",
        "    before_except_idx = 0\n",
        "    \n",
        "    for i, combo in enumerate(tqdm(combo_list[s:e]), start=s):\n",
        "        new_combo, tokenized_result = extract_nouns(google_searcher, combo)\n",
        "        if new_combo:\n",
        "            nouns_list.append((combo, new_combo, tokenized_result))\n",
        "        else:\n",
        "            if tokenized_result == 'zero_noun': # 명사가 전혀 없는경우\n",
        "                zero_noun_list.append(combo)\n",
        "            elif tokenized_result == 'no_minimal_element': # 가장 잘게짜른 토큰화가 나머지 토큰화를 포함 못하는 경우\n",
        "                except_combo_list.append(combo)\n",
        "            elif tokenized_result == 'search_failed': # 크롤링 실패\n",
        "                if before_except_idx +1 == i:\n",
        "                    print(f'close : {combo}, end index : {i}')\n",
        "                    e = i\n",
        "                    break\n",
        "                else:\n",
        "                    before_except_idx = i\n",
        "                    except_combo_list.append(combo)\n",
        "\n",
        "        if i%1000 == 0 and i != s:\n",
        "            data = {'nouns_list':nouns_list, \n",
        "                    'zero_noun_list':zero_noun_list,\n",
        "                    'except_combo_list':except_combo_list}\n",
        "            save(data, s, i)\n",
        "\n",
        "\n",
        "    print(f'nouns_list length: {len(nouns_list)}')\n",
        "    print(f'zero_noun_list length: {len(zero_noun_list)}')\n",
        "    print(f'except_combo_list length: {len(except_combo_list)}')\n",
        "\n",
        "    data = {'nouns_list':nouns_list, \n",
        "            'zero_noun_list':zero_noun_list,\n",
        "            'except_combo_list':except_combo_list}\n",
        "\n",
        "    return data, s, e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN88cqJlExSJ"
      },
      "source": [
        "import pickle\n",
        "\n",
        "def save(data, s, e, path='/content/drive/MyDrive/save/extracted'):\n",
        "    with open(f'{path}_{len(combo_list)}_{s}_{e}.pickle', 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "    nouns_list = clean_nouns_list(data['nouns_list'])\n",
        "\n",
        "    with open(f'{path}_nouns_{len(combo_list)}_{s}_{e}.pickle', 'wb') as f:\n",
        "        pickle.dump(nouns_list, f)\n",
        "\n",
        "    return nouns_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRZQAAk-KqlW"
      },
      "source": [
        "### 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "8a79b5a56b1442f4a5fe897aa5a6e5b8",
            "c541acf2fde94bfcb0a299a68fe8d23c",
            "4c7c623585554730812d0f28e0c94ac6",
            "1033f18c2fbf4631bf2b0a704577670e",
            "f063e17c4ae5417bb04de691de502b7e",
            "18d26a05c4bc4a53b818dd8f8ff10e10",
            "098516d2ef0d4f10a1c5b4c36ac8726b",
            "c7c5bf47d48c48d5823b604a1df4f78d",
            "e2645762dc88406eaed2584f13d05514",
            "54c888fd886241e68789e90661eae42d",
            "aba3dccbc77e4edaa6094e1d404958b0"
          ]
        },
        "id": "eAJQ7MGyBjdO",
        "outputId": "2266a74c-81f9-453a-c6b8-32817b848932"
      },
      "source": [
        "s = 0\n",
        "e = 100\n",
        "data, s, e = tokenize(combo_list, s, e)\n",
        "nouns_list = save(data, s, e)\n",
        "print(s)\n",
        "print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a79b5a56b1442f4a5fe897aa5a6e5b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nouns_list length: 98\n",
            "zero_noun_list length: 0\n",
            "except_combo_list length: 2\n",
            "0\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBaq_3BrPN70",
        "outputId": "7a842350-eda8-4b59-97dd-65dc19de9be3"
      },
      "source": [
        "nouns_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('천안정비사업소', [('천안정비사업소', '천안정비사업소', [[(0, '천안정비사업소', 11)]])]),\n",
              " ('포켓', [('포켓', '포켓', [[(0, '포켓', 7)]])]),\n",
              " ('블랙박스카드', [('블랙박스카드', '블랙박스카드', [[(0, '블랙박스', 30), (4, '카드', 15)]])]),\n",
              " ('차액', [('차액', '차액', [[(0, '차액', 6)]])]),\n",
              " ('단말기신호', [('단말기신호', '단말기신호', [[(0, '단말기', 21), (3, '신호', 13)]])]),\n",
              " ('사제', [('사제', '사제', [[(0, '사제', 9)]])]),\n",
              " ('담배냄새', [('담배냄새', '담배냄새', [[(0, '담배', 23), (2, '냄새', 12)]])]),\n",
              " ('진입', [('진입', '진입', [[(0, '진입', 15)]])]),\n",
              " ('범버', [('범버', '범버', [[(0, '범버', 12)]])]),\n",
              " ('카수리', [('카수리', '카수리', [[(0, '카수리', 7)]])]),\n",
              " ('연결선', [('연결선', '연결선', [[(0, '연결선', 16)]])]),\n",
              " ('시동확인완료',\n",
              "  [('시동확인완료', '시동확인완료', [[(0, '시동', 35), (2, '확인', 23), (4, '완료', 12)]])]),\n",
              " ('퓨즈교환하니', [('퓨즈교환', '퓨즈교환', [[(0, '퓨즈', 25), (2, '교환', 12)]])]),\n",
              " ('주차완료',\n",
              "  [('주차완료', '주차완료', [[(0, '주차', 13), (2, '완료', 6)], [(0, '주차완료', 1)]])]),\n",
              " ('앞유리에', [('앞유리', '앞유리', [[(0, '앞', 13), (1, '유리', 10)], [(0, '앞유리', 9)]])]),\n",
              " ('테스트주행시', [('테스트주행시', '테스트주행시', [[(0, '테스트', 9), (3, '주행시', 1)]])]),\n",
              " ('시도', [('시도', '시도', [[(0, '시도', 10)]])]),\n",
              " ('도어몰딩',\n",
              "  [('도어몰딩', '도어몰딩', [[(0, '도어', 15), (2, '몰딩', 8)], [(0, '도어몰딩', 7)]])]),\n",
              " ('문제어안됨', [('문제어', '문제어', [[(0, '문제', 17), (2, '어', 4)]])]),\n",
              " ('후진시에', [('후진시', '후진시', [[(0, '후진', 14), (2, '시', 9)], [(0, '후진시', 10)]])]),\n",
              " ('시운전공임', [('시운전공임', '시운전공임', [[(0, '시운전', 20), (3, '공임', 8)]])]),\n",
              " ('장애없고', [('장애', '장애', [[(0, '장애', 17)]])]),\n",
              " ('서비스센터입고예정',\n",
              "  [('서비스센터입고예정',\n",
              "    '서비스센터입고예정',\n",
              "    [[(0, '서비스', 20), (3, '센터', 16), (5, '입고', 9), (7, '예정', 3)],\n",
              "     [(0, '서비스', 20), (3, '센터', 16), (5, '입고예정', 2)],\n",
              "     [(0, '서비스센터', 10), (5, '입고', 9), (7, '예정', 3)],\n",
              "     [(0, '서비스센터', 10), (5, '입고예정', 2)]])]),\n",
              " ('절연테이프조치',\n",
              "  [('절연테이프조치',\n",
              "    '절연테이프조치',\n",
              "    [[(0, '절연', 9), (2, '테이프', 8), (5, '조치', 6)],\n",
              "     [(0, '절연테이프', 13), (5, '조치', 6)]])]),\n",
              " ('거치대교체완료',\n",
              "  [('거치대교체완료',\n",
              "    '거치대교체완료',\n",
              "    [[(0, '거치대', 21), (3, '교체', 15), (5, '완료', 8)],\n",
              "     [(0, '거치대', 21), (3, '교체완료', 1)]])]),\n",
              " ('개문으로', [('개문', '개문', [[(0, '개문', 15)]])]),\n",
              " ('분실', [('분실', '분실', [[(0, '분실', 11)]])]),\n",
              " ('방향지시등',\n",
              "  [('방향지시등', '방향지시등', [[(0, '방향', 7), (2, '지시등', 2)], [(0, '방향지시등', 13)]])]),\n",
              " ('지렁이', [('지렁이', '지렁이', [[(0, '지렁이', 15)]])]),\n",
              " ('미션교환완료',\n",
              "  [('미션교환완료',\n",
              "    '미션교환완료',\n",
              "    [[(0, '미션', 24), (2, '교환', 11), (4, '완료', 3)],\n",
              "     [(0, '미션', 24), (2, '교환완료', 1)]])]),\n",
              " ('안내', [('안내', '안내', [[(0, '안내', 11)]])]),\n",
              " ('작동시', [('작동시', '작동시', [[(0, '작동', 8), (2, '시', 2)], [(0, '작동시', 4)]])]),\n",
              " ('더뉴레이', [('더뉴레이', '더뉴레이', [[(0, '더', 16), (1, '뉴', 16), (2, '레이', 9)]])]),\n",
              " ('손상없음', [('손상', '손상', [[(0, '손상', 11)]])]),\n",
              " ('동작반응없음', [('동작반응', '동작반응', [[(0, '동작', 12), (2, '반응', 6)]])]),\n",
              " ('작동되지', [('작동되지', '작동되지', [[(0, '작동되지', 11)]])]),\n",
              " ('목포', [('목포', '목포', [[(0, '목포', 17)]])]),\n",
              " ('점검결과',\n",
              "  [('점검결과', '점검결과', [[(0, '점검', 16), (2, '결과', 8)], [(0, '점검결과', 2)]])]),\n",
              " ('인근', [('인근', '인근', [[(0, '인근', 13)]])]),\n",
              " ('글로브박스에보관중',\n",
              "  [('글로브박스', '글로브박스', [[(0, '글로브', 27), (3, '박스', 25)], [(0, '글로브박스', 24)]]),\n",
              "   ('보관중', '보관중', [[(6, '보관', 13), (8, '중', 6)]])]),\n",
              " ('퓨즈커넥터',\n",
              "  [('퓨즈커넥터', '퓨즈커넥터', [[(0, '퓨즈', 13), (2, '커넥터', 8)], [(0, '퓨즈커넥터', 1)]])]),\n",
              " ('재진행', [('재진행', '재진행', [[(0, '재진행', 8)]])]),\n",
              " ('구토오염', [('구토오염', '구토오염', [[(0, '구토', 15), (2, '오염', 8)]])]),\n",
              " ('스롤틀바디',\n",
              "  [('스롤틀바디', '스로틀바디', [[(0, '스로틀', 12), (3, '바디', 7)], [(0, '스로틀바디', 3)]])]),\n",
              " ('오일필터',\n",
              "  [('오일필터', '오일필터', [[(0, '오일', 7), (2, '필터', 3)], [(0, '오일필터', 7)]])]),\n",
              " ('조라이트전구',\n",
              "  [('조라이트전구',\n",
              "    '조라이트전구',\n",
              "    [[(0, '조', 32), (1, '라이트', 24), (4, '전구', 11)],\n",
              "     [(0, '조', 32), (1, '라이트전구', 3)]])]),\n",
              " ('정상작동확인완료',\n",
              "  [('정상작동확인완료',\n",
              "    '정상작동확인완료',\n",
              "    [[(0, '정상', 27), (2, '작동', 22), (4, '확인', 17), (6, '완료', 8)],\n",
              "     [(0, '정상', 27), (2, '작동', 22), (4, '확인완료', 2)],\n",
              "     [(0, '정상작동', 21), (4, '확인', 17), (6, '완료', 8)],\n",
              "     [(0, '정상작동', 21), (4, '확인완료', 2)]])]),\n",
              " ('의견', [('의견', '의견', [[(0, '의견', 16)]])]),\n",
              " ('임시고정은',\n",
              "  [('임시고정은',\n",
              "    '임시고정은',\n",
              "    [[(0, '임시', 22), (2, '고정', 16), (4, '은', 10)],\n",
              "     [(0, '임시고정', 13), (4, '은', 10)]])]),\n",
              " ('공기압점검', [('공기압점검', '공기압점검', [[(0, '공기압', 18), (3, '점검', 6)]])]),\n",
              " ('차량위치',\n",
              "  [('차량위치', '차량위치', [[(0, '차량', 23), (2, '위치', 12)], [(0, '차량위치', 1)]])]),\n",
              " ('공기압낮아', [('공기압낮아', '공기압낮아', [[(0, '공기압', 28), (3, '낮아', 7)]])]),\n",
              " ('열', [('열', '열', [[(0, '열', -1)]])]),\n",
              " ('전구류도', [('전구류', '전구류', [[(0, '전구류', 15)]])]),\n",
              " ('경고등점등없으며', [('경고등점등', '경고등점등', [[(0, '경고등', 18), (3, '점등', 8)]])]),\n",
              " ('하이패스카드', [('하이패스카드', '하이패스카드', [[(0, '하이패스', 32), (4, '카드', 15)]])]),\n",
              " ('외부에', [('외부', '외부', [[(0, '외부', 2)]])]),\n",
              " ('일반', [('일반', '일반', [[(0, '일반', 10)]])]),\n",
              " ('에어컨에서', [('에어컨', '에어컨', [[(0, '에어컨', 5)]])]),\n",
              " ('뒷번호판',\n",
              "  [('뒷번호판', '뒷번호판', [[(0, '뒷', 6), (1, '번호판', 3)], [(0, '뒷번호판', 7)]])]),\n",
              " ('차량위치오류',\n",
              "  [('차량위치오류',\n",
              "    '차량위치오류',\n",
              "    [[(0, '차량', 31), (2, '위치', 21), (4, '오류', 8)],\n",
              "     [(0, '차량위치', 9), (4, '오류', 8)]])]),\n",
              " ('완료및', [('완료및', '완료및', [[(0, '완료', 21), (2, '및', 10)]])]),\n",
              " ('시트완전분해',\n",
              "  [('시트완전분해',\n",
              "    '시트완전분해',\n",
              "    [[(0, '시트', 24), (2, '완전', 12), (4, '분해', 8)],\n",
              "     [(0, '시트', 24), (2, '완전분해', 2)]])]),\n",
              " ('키드', [('키드', '키드', [[(0, '키드', 13)]])]),\n",
              " ('수령후', [('수령후', '수령후', [[(0, '수령', 18), (2, '후', 9)], [(0, '수령후', 2)]])]),\n",
              " ('뒷자리매트',\n",
              "  [('뒷자리매트', '뒷자리매트', [[(0, '뒷자리', 30), (3, '매트', 28)], [(0, '뒷자리매트', 1)]])]),\n",
              " ('쌍용인천정비사업소',\n",
              "  [('쌍용', '쌍용', [[(0, '쌍용', 18)]]),\n",
              "   ('정비사업소', '정비사업소', [[(4, '정비', 2), (6, '사업소', 1)], [(4, '정비사업소', 1)]])]),\n",
              " ('리터', [('리터', '리터', [[(0, '리터', 9)]])]),\n",
              " ('키아웃점검',\n",
              "  [('키아웃점검', '키아웃점검', [[(0, '키', 29), (1, '아웃', 18), (3, '점검', 10)]])]),\n",
              " ('퀵비', [('퀵비', '퀵비', [[(0, '퀵비', 5)]])]),\n",
              " ('컵홀더', [('컵홀더', '컵홀더', [[(0, '컵홀더', 9)]])]),\n",
              " ('동물발자국',\n",
              "  [('동물발자국', '동물발자국', [[(0, '동물', 15), (2, '발자국', 7)], [(0, '동물발자국', 3)]])]),\n",
              " ('쪽에', [('쪽에', '쪽에', [[(0, '쪽에', 6)]])]),\n",
              " ('부산부기산업',\n",
              "  [('부산부기산업',\n",
              "    '부산부기산업',\n",
              "    [[(0, '부산', 5), (2, '부기산업', 1)], [(0, '부산부기산업', 7)]])]),\n",
              " ('하부연료호스고정',\n",
              "  [('하부연료호스고정',\n",
              "    '하부연료호스고정',\n",
              "    [[(0, '하부', 28), (2, '연료', 23), (4, '호스', 12), (6, '고정', 6)],\n",
              "     [(0, '하부', 28), (2, '연료호스', 9), (6, '고정', 6)]])]),\n",
              " ('교체후', [('교체후', '교체후', [[(0, '교체', 12), (2, '후', 5)], [(0, '교체후', 1)]])]),\n",
              " ('주차위치에서',\n",
              "  [('주차위치', '주차위치', [[(0, '주차', 21), (2, '위치', 12)], [(0, '주차위치', 10)]])]),\n",
              " ('데루등', [('데루등', '데루등', [[(0, '데루등', 24)]])]),\n",
              " ('마감재교환', [('마감재교환', '마감재교환', [[(0, '마감재', 12), (3, '교환', 3)]])]),\n",
              " ('시트와', [('시트', '시트', [[(0, '시트', 13)]])]),\n",
              " ('부품도착시', [('부품', '부품', [[(0, '부품', 21)]]), ('시', '시', [[(4, '시', 7)]])]),\n",
              " ('점멸이상무', [('점멸이상무', '점멸이상무', [[(0, '점멸', 15), (2, '이상무', 4)]])]),\n",
              " ('아닌곳에', [('아닌곳', '아닌곳', [[(0, '아닌', 17), (2, '곳', 3)]])]),\n",
              " ('차체떨림소리', [('차체', '차체', [[(0, '차체', 18)]]), ('소리', '소리', [[(4, '소리', 5)]])]),\n",
              " ('해저드', [('해저드', '해저드', [[(0, '해저드', 19)]])]),\n",
              " ('장착후', [('장착후', '장착후', [[(0, '장착', 13), (2, '후', 6)], [(0, '장착후', 1)]])]),\n",
              " ('차체', [('차체', '차체', [[(0, '차체', 15)]])]),\n",
              " ('전좌타이어교체',\n",
              "  [('전좌타이어교체', '전좌타이어교체', [[(0, '전좌', 29), (2, '타이어', 19), (5, '교체', 8)]])]),\n",
              " ('굳음상태', [('굳음상태', '굳음상태', [[(0, '굳음', 19), (2, '상태', 12)]])]),\n",
              " ('경고등점등', [('경고등점등', '경고등점등', [[(0, '경고등', 16), (3, '점등', 7)]])]),\n",
              " ('함', [('함', '함', [[(0, '함', -1)]])]),\n",
              " ('음영구역의심됨',\n",
              "  [('음영구역의심', '음영구역의심', [[(0, '음영', 26), (2, '구역', 21), (4, '의심', 9)]])]),\n",
              " ('속커버', [('속커버', '속커버', [[(0, '속커버', 14)]])]),\n",
              " ('만석으로', [('만석', '만석', [[(0, '만석', 19)]])]),\n",
              " ('유지중입니다', [('유지중', '유지중', [[(0, '유지', 9), (2, '중', 7)]])]),\n",
              " ('로워암이', [('로워암', '로워암', [[(0, '로워암', 9)]])]),\n",
              " ('앞라이트전구',\n",
              "  [('앞라이트전구',\n",
              "    '앞라이트전구',\n",
              "    [[(0, '앞', 28), (1, '라이트', 28), (4, '전구', 14)],\n",
              "     [(0, '앞', 28), (1, '라이트전구', 3)]])]),\n",
              " ('네비전원잭',\n",
              "  [('네비전원잭', '네비전원잭', [[(0, '네비', 5), (2, '전원잭', 3)], [(0, '네비전원잭', 1)]])])]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyZa7XXP_Xft"
      },
      "source": [
        "import glob \n",
        "\n",
        "def merge_file_and_save(condition_path):\n",
        "    s = ''\n",
        "\n",
        "    for filepath in glob.glob(f'{condition_path}_*'):\n",
        "        with open(filepath, 'r') as f:\n",
        "            s += '\\n' + f.read()\n",
        "\n",
        "    with open(f'{condition_path}.txt', 'w') as f:\n",
        "        f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlMdtWviAk78"
      },
      "source": [
        "# merge_file_and_save('/content/drive/MyDrive/extracted_nouns_7251')\n",
        "# merge_file_and_save('/content/drive/MyDrive/extracted_infos_7251')\n",
        "# merge_file_and_save('/content/drive/MyDrive/extracted_except_7251')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}